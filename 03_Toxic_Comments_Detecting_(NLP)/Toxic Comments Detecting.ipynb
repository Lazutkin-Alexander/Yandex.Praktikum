{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение токсичных комментариев\n",
    "\n",
    "Дан крупный набор комментариев на английском с разметкой о токсичности.\n",
    "Необходимо построить модель классификации со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "Структура исходных данных:\n",
    "- text - текст комментария\n",
    "- toxic — целевой признак (1 - токсичный комментарий, 0 - обычный комментарий)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт необходимых библиотек:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Считывание файла с данными, первые несколько строк таблицы:\n",
    "comments_data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "comments_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Основная информация:\n",
    "comments_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rex Mundi \\n\\nI've created a stub on Rex Mundi at Rex Mundi High School.  Only thing I know about it is that both my Aunt Donna and Bob Griese went there.  Please add anything you might know about it.\\n\\nBTW, my dad was a Panther; I live in Princeton myself.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Пример комментария:\n",
    "comments_data.loc[1000]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные содержат 159571 комментарий с пометкой о токсичности. Пропусков в данных нет. В комментариях есть прописные и строчные буквы, алгоритмы токенизации могут принять слова с буквами в разных регистрах за разные слова, поэтому все буквы я приведу к нижнему регистру. Также можно заметить, что в сообщениях часто встречается последовательность символов \\n - скорее всего это специальные символы, отвечающие за перенос строки, их лучше удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Замена символов \\n на пробел (пробел, а не пустота, чтобы слова не слипались):\n",
    "comments_data['text'] = comments_data['text'].apply(lambda x: x.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем заменять все большие буквы на маленькие, посмотрю нет ли зависимости между большим количеством прописных букв в комментарии и токсичностью - оскорбительные комментарии могут писаться капслоком. Кроме того, хочется проверить как длина сообщения соотносится с токсичностью - возможно грубые комментарии очень короткие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orange'> \n",
    "*Когда я выполнял этот проект, мне показалось хорошей идеей использовать коэффициент корреляции Пирсона. Теперь я понимаю, что использовать его для категориальных данных некорректно*\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0516960635833761"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Добавление столбца с длиной сообщения:\n",
    "comments_data['len'] = comments_data['text'].apply(len)\n",
    "\n",
    "#Коэффициент корреляции между длиной сообщения и его токсичностью:\n",
    "comments_data['len'].corr(comments_data['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Длина сообщения почти не коррелирует с токсичностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2981</td>\n",
       "      <td>cocksucking bastard</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17973</td>\n",
       "      <td>ya mum   fucks ya</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19789</td>\n",
       "      <td>One word: freaks. -</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22778</td>\n",
       "      <td>Fuck you   Fuck you</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23611</td>\n",
       "      <td>questions cuntface!</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26794</td>\n",
       "      <td>YOU ARE AN ASSHOLE</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33771</td>\n",
       "      <td>alex fuck you   ...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46949</td>\n",
       "      <td>You're such a slut.</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60495</td>\n",
       "      <td>WHY YOU SO PIG??</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60971</td>\n",
       "      <td>Get lost   Get lost</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63653</td>\n",
       "      <td>CANT BLOCK ME NIGGA</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95808</td>\n",
       "      <td>^No it wasn't. Wtf.</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100706</td>\n",
       "      <td>hello cow head</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103210</td>\n",
       "      <td>PS, you're a bitch.</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109287</td>\n",
       "      <td>fuck you   fuck you</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text  toxic  len\n",
       "2981    cocksucking bastard      1   19\n",
       "17973     ya mum   fucks ya      1   17\n",
       "19789   One word: freaks. -      1   19\n",
       "22778   Fuck you   Fuck you      1   19\n",
       "23611   questions cuntface!      1   19\n",
       "26794    YOU ARE AN ASSHOLE      1   18\n",
       "33771   alex fuck you   ...      1   19\n",
       "46949   You're such a slut.      1   19\n",
       "60495      WHY YOU SO PIG??      1   16\n",
       "60971   Get lost   Get lost      1   19\n",
       "63653   CANT BLOCK ME NIGGA      1   19\n",
       "95808   ^No it wasn't. Wtf.      1   19\n",
       "100706       hello cow head      1   14\n",
       "103210  PS, you're a bitch.      1   19\n",
       "109287  fuck you   fuck you      1   19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Вывод некоторых коротких оскорбительных комментариев. Можно найти какие-нибудь неочевидные сходства таких комментариев.\n",
    "comments_data[(comments_data['len'] < 20) & (comments_data['toxic'] == 1)].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>899</td>\n",
       "      <td>I've just seen that</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>Is it still a stub?</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2461</td>\n",
       "      <td>- unsigned comment</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2506</td>\n",
       "      <td>I understand now.</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2823</td>\n",
       "      <td>Sure, goodnight! )</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3354</td>\n",
       "      <td>Agreed and done.</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3595</td>\n",
       "      <td>comments on draft 2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3638</td>\n",
       "      <td>September 2008</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4424</td>\n",
       "      <td>And quote from it</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5145</td>\n",
       "      <td>3rd Unblock Request</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5394</td>\n",
       "      <td>Thanks, Dr. B and .</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5670</td>\n",
       "      <td>Template:Nn-warn &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6002</td>\n",
       "      <td>That works too. ;)</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6493</td>\n",
       "      <td>No problem. Thanks,</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6596</td>\n",
       "      <td>I've not got a Mac.</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text  toxic  len\n",
       "899   I've just seen that      0   19\n",
       "1275  Is it still a stub?      0   19\n",
       "2461   - unsigned comment      0   18\n",
       "2506    I understand now.      0   17\n",
       "2823   Sure, goodnight! )      0   18\n",
       "3354     Agreed and done.      0   16\n",
       "3595  comments on draft 2      0   19\n",
       "3638       September 2008      0   14\n",
       "4424    And quote from it      0   17\n",
       "5145  3rd Unblock Request      0   19\n",
       "5394  Thanks, Dr. B and .      0   19\n",
       "5670   Template:Nn-warn >      0   18\n",
       "6002   That works too. ;)      0   18\n",
       "6493  No problem. Thanks,      0   19\n",
       "6596  I've not got a Mac.      0   19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Для сравнения вывод корректных коротких комментариев:\n",
    "comments_data[(comments_data['len'] < 20) & (comments_data['toxic'] == 0)].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно, на этой небольшой выборке комментариев видно, что в токсичных комментариях частенько используется капслок. В корректных комментариях в конце пользователи могут ставить ')' или смайлик с этой скобкой. Можно предположить, что в токсичных комментариях чаще будет использоваться восклицательный знак. Добавлю столбцы с новыми признаками и проверю корреляцию их с токсичностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 19.7 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2153173791222518"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Функция расчета соотношения количества прописных букв и всех символов в тексте:\n",
    "def upper_case_ratio(entry):\n",
    "    \n",
    "    length = entry['len']\n",
    "    upper = 0\n",
    "    text_list = list(entry['text'])\n",
    "    \n",
    "    for i in text_list:\n",
    "        if i.isupper():\n",
    "            upper += 1\n",
    "            \n",
    "    return upper/length\n",
    "\n",
    "#Добавление соотношения прописных букв и символов в тексте к таблице:\n",
    "comments_data['uppercase_ratio'] = comments_data.apply(upper_case_ratio, axis=1)\n",
    "\n",
    "#Коэффициент корреляции между новым признаком и токсичностью:\n",
    "comments_data['uppercase_ratio'].corr(comments_data['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть положительная корреляция между новым признаком и токсичностью комментария."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "      <th>uppercase_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11796</td>\n",
       "      <td>==U R GAY==   FUCKFUCKFUCKFUCKFUCKFUCKFUCKFUCK...</td>\n",
       "      <td>1</td>\n",
       "      <td>4969</td>\n",
       "      <td>0.998189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34637</td>\n",
       "      <td>shut up you cunt WWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
       "      <td>1</td>\n",
       "      <td>4177</td>\n",
       "      <td>0.995930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29580</td>\n",
       "      <td>YO MOMA IS COOL AND FARTS 247   HI BYE GIGOWNG...</td>\n",
       "      <td>1</td>\n",
       "      <td>459</td>\n",
       "      <td>0.969499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106067</td>\n",
       "      <td>FFFFFFFFFFFFFFFUUUUUUUUUUUUUUUUUUUUUUUCCCCCCCC...</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>0.965116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71584</td>\n",
       "      <td>MRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRR...</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21366</td>\n",
       "      <td>I SAID GOOD DAY BIATCH DONT BREAK WP:3RR BIATC...</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>0.959064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40851</td>\n",
       "      <td>Discussion destroying CRAP topic   It seems th...</td>\n",
       "      <td>1</td>\n",
       "      <td>4957</td>\n",
       "      <td>0.951584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22657</td>\n",
       "      <td>\"   find the \"\"W\"\"   MMMMMMMMMMMMMMMMMMMMMMMMM...</td>\n",
       "      <td>0</td>\n",
       "      <td>422</td>\n",
       "      <td>0.950237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113646</td>\n",
       "      <td>HA GAAAAAAAAAYYYYY</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108142</td>\n",
       "      <td>BLAHBLAHBLAHBLAHNLAHNLAHBLAHBLHA AND STOP CHAN...</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0.931373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1876</td>\n",
       "      <td>YOUR ARE FUCKING GAY WAD!!!!!!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>4897</td>\n",
       "      <td>0.923423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157538</td>\n",
       "      <td>DONT MESS WITH AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>0.922414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107304</td>\n",
       "      <td>SHUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUT UP MY AW...</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0.920635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40223</td>\n",
       "      <td>STUPID SPANISH CENTRALISTSTUPID SPANISH CENTRA...</td>\n",
       "      <td>1</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78429</td>\n",
       "      <td>WORST CUSTOMER SERVICE EVARRRRRRRRR</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic   len  \\\n",
       "11796   ==U R GAY==   FUCKFUCKFUCKFUCKFUCKFUCKFUCKFUCK...      1  4969   \n",
       "34637   shut up you cunt WWWWWWWWWWWWWWWWWWWWWWWWWWWWW...      1  4177   \n",
       "29580   YO MOMA IS COOL AND FARTS 247   HI BYE GIGOWNG...      1   459   \n",
       "106067  FFFFFFFFFFFFFFFUUUUUUUUUUUUUUUUUUUUUUUCCCCCCCC...      1    86   \n",
       "71584   MRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRR...      0   189   \n",
       "21366   I SAID GOOD DAY BIATCH DONT BREAK WP:3RR BIATC...      1   342   \n",
       "40851   Discussion destroying CRAP topic   It seems th...      1  4957   \n",
       "22657   \"   find the \"\"W\"\"   MMMMMMMMMMMMMMMMMMMMMMMMM...      0   422   \n",
       "113646                                 HA GAAAAAAAAAYYYYY      1    18   \n",
       "108142  BLAHBLAHBLAHBLAHNLAHNLAHBLAHBLHA AND STOP CHAN...      1   102   \n",
       "1876    YOUR ARE FUCKING GAY WAD!!!!!!!!!!!!!!!!!!!!!!...      1  4897   \n",
       "157538  DONT MESS WITH AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...      1   116   \n",
       "107304  SHUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUT UP MY AW...      1    63   \n",
       "40223   STUPID SPANISH CENTRALISTSTUPID SPANISH CENTRA...      1  4500   \n",
       "78429                 WORST CUSTOMER SERVICE EVARRRRRRRRR      1    35   \n",
       "\n",
       "        uppercase_ratio  \n",
       "11796          0.998189  \n",
       "34637          0.995930  \n",
       "29580          0.969499  \n",
       "106067         0.965116  \n",
       "71584          0.962963  \n",
       "21366          0.959064  \n",
       "40851          0.951584  \n",
       "22657          0.950237  \n",
       "113646         0.944444  \n",
       "108142         0.931373  \n",
       "1876           0.923423  \n",
       "157538         0.922414  \n",
       "107304         0.920635  \n",
       "40223          0.920000  \n",
       "78429          0.914286  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Вывод комментариев с самым большим соотношением больших букв к символам:\n",
    "comments_data.sort_values(by='uppercase_ratio', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "      <th>uppercase_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>79785</td>\n",
       "      <td>(who atleast had a degree in history)</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5947</td>\n",
       "      <td>what's with undoing those changes?</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23164</td>\n",
       "      <td>dick shit cock fuck   you are a fag  you are a...</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23181</td>\n",
       "      <td>they're back!  anyone have a screencap from ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93601</td>\n",
       "      <td>its not me whos doing this. believe me.</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93600</td>\n",
       "      <td>because he is a punk hu loves wow he is a big ...</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93598</td>\n",
       "      <td>su.cked my c.ock last night</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93588</td>\n",
       "      <td>co/ck - pen-i.s. international</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142615</td>\n",
       "      <td>inject energy into these arrangements making t...</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93586</td>\n",
       "      <td>{{unblock|yo</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93563</td>\n",
       "      <td>now you're saying im not logical? when do thes...</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23210</td>\n",
       "      <td>go ahead   i don't give a shit to that</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23211</td>\n",
       "      <td>, or even that he has a girlfriend</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93683</td>\n",
       "      <td>why ae you deleting my edits, they arent vanda...</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5930</td>\n",
       "      <td>charlie herridge 13 year old</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  len  \\\n",
       "79785               (who atleast had a degree in history)      0   37   \n",
       "5947                   what's with undoing those changes?      0   34   \n",
       "23164   dick shit cock fuck   you are a fag  you are a...      1  207   \n",
       "23181   they're back!  anyone have a screencap from ar...      0   59   \n",
       "93601             its not me whos doing this. believe me.      0   39   \n",
       "93600   because he is a punk hu loves wow he is a big ...      1   58   \n",
       "93598                         su.cked my c.ock last night      1   27   \n",
       "93588                      co/ck - pen-i.s. international      1   30   \n",
       "142615  inject energy into these arrangements making t...      0   56   \n",
       "93586                                        {{unblock|yo      0   12   \n",
       "93563   now you're saying im not logical? when do thes...      0  299   \n",
       "23210              go ahead   i don't give a shit to that      1   38   \n",
       "23211                  , or even that he has a girlfriend      0   34   \n",
       "93683   why ae you deleting my edits, they arent vanda...      0  107   \n",
       "5930                         charlie herridge 13 year old      0   28   \n",
       "\n",
       "        uppercase_ratio  \n",
       "79785               0.0  \n",
       "5947                0.0  \n",
       "23164               0.0  \n",
       "23181               0.0  \n",
       "93601               0.0  \n",
       "93600               0.0  \n",
       "93598               0.0  \n",
       "93588               0.0  \n",
       "142615              0.0  \n",
       "93586               0.0  \n",
       "93563               0.0  \n",
       "23210               0.0  \n",
       "23211               0.0  \n",
       "93683               0.0  \n",
       "5930                0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#И для сравнения вывод комментариев без больших букв:\n",
    "comments_data.sort_values(by='uppercase_ratio').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что новый признак неплохо делит комментарии на токсичные и корректные. У меня появилось еще несколько предположений:\n",
    "- В токсичных комментариях много повторов одного символа подряд\n",
    "- В токсичных комментариях оскорбительные слова маскируются - буквы в нем перемежаются знаками препинания и особыми символами - их нужно удалить, чтобы токенизация сработала лучше\n",
    "- Можно \"схлопнуть\" комментарии за счет повторяющихся символов - так, чтобы символы не повторялись более двух раз подряд. В дальнейшем это также положительно скажется на создании токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 59.4 ms, total: 15.1 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Функция для расчета соотношения повторяющихся символов и всех символов в тексте:\n",
    "def repeat_letters_ratio(entry):\n",
    "    \n",
    "    length = entry['len']\n",
    "    repeated = 0\n",
    "    text_list = list(entry['text'])\n",
    "    \n",
    "    for i in range(len(text_list)-1):\n",
    "        if text_list[i] == text_list[i+1]:\n",
    "            repeated += 1\n",
    "            \n",
    "    return repeated/length\n",
    "\n",
    "#Применение функции и создание нового признака:\n",
    "comments_data['repeat_letters_ratio'] = comments_data.apply(repeat_letters_ratio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.39 s, sys: 43.8 ms, total: 9.43 s\n",
      "Wall time: 9.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Функция для расчета соотношения восклицательных знаков и всех символов в тексте:\n",
    "def exclamation_point_ratio(entry):\n",
    "    \n",
    "    length = entry['len']\n",
    "    exclamation_point = 0\n",
    "    text_list = list(entry['text'])\n",
    "    \n",
    "    for i in text_list:\n",
    "        if i == '!':\n",
    "            exclamation_point += 1\n",
    "            \n",
    "    return exclamation_point/length\n",
    "\n",
    "#Применение функции:\n",
    "comments_data['exclamation_point_ratio'] = comments_data.apply(exclamation_point_ratio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.58 s, sys: 35.9 ms, total: 9.61 s\n",
      "Wall time: 9.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Функция для расчета соотношения закрывающей скобки и всех символов в тексте:\n",
    "def closing_bracket_ratio(entry):\n",
    "    \n",
    "    length = entry['len']\n",
    "    closing_bracket = 0\n",
    "    text_list = list(entry['text'])\n",
    "    \n",
    "    for i in text_list:\n",
    "        if i == ')':\n",
    "            closing_bracket += 1\n",
    "            \n",
    "    return closing_bracket/length\n",
    "\n",
    "#Применение функции:\n",
    "comments_data['closing_bracket_ratio'] = comments_data.apply(closing_bracket_ratio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic                      1.000000\n",
       "len                       -0.051696\n",
       "uppercase_ratio            0.215317\n",
       "repeat_letters_ratio       0.110791\n",
       "exclamation_point_ratio    0.129425\n",
       "closing_bracket_ratio     -0.075592\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Коэффициенты корреляции новых признаков и токсичности:\n",
    "comments_data.corr()['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задамся порогом коэффициента корреляции 0.1 и удалю признаки, показавшие небольшую связь с целевым признаком. И продолжу обработку данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаление лишних признаков:\n",
    "comments_data.drop(['len', 'closing_bracket_ratio'], axis=1, inplace=True)\n",
    "\n",
    "#Удаление знаков пунктуации из комментариев (и склеивание зашифрованных слов):\n",
    "tt = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "comments_data['text'] = comments_data['text'].apply(lambda x: x.translate(tt))\n",
    "\n",
    "#Перевод букв в нижний регистр:\n",
    "comments_data['text'] = comments_data['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 31.9 ms, total: 19.9 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Функция для удаления символов, повторяющихся подряд более 2 раз:\n",
    "def max_repeat_letters_2(string):\n",
    "    \n",
    "    if len(string) < 3:\n",
    "        return string\n",
    "    \n",
    "    new_str = ''\n",
    "    \n",
    "    for i in range(len(string)-2):\n",
    "        \n",
    "        i1 = i\n",
    "        i2 = i + 1\n",
    "        i3 = i + 2\n",
    "        \n",
    "        if string[i1] != string[i2]:\n",
    "            new_str = new_str + string[i1]\n",
    "        else:\n",
    "            if string[i2] != string[i3]:\n",
    "                new_str = new_str + string[i1]\n",
    "                \n",
    "    new_str = new_str + string[-2] + string[-1]\n",
    "                \n",
    "    return new_str\n",
    "\n",
    "#Применение функции к комментариям:\n",
    "comments_data['text'] = comments_data['text'].apply(max_repeat_letters_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 819 ms, sys: 4.03 ms, total: 823 ms\n",
      "Wall time: 833 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Функция для удаления всех символов, кроме латинских букв в тексте:\n",
    "def only_latin(string):\n",
    "    \n",
    "    words = re.sub(r'[^a-zA-Z ]', '', string)\n",
    "    \n",
    "    return words\n",
    "\n",
    "#Применение функции:\n",
    "comments_data['text'] = comments_data['text'].apply(only_latin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 32s, sys: 216 ms, total: 2min 32s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Стемминг каждого слова в тексте:\n",
    "def stemming(text):\n",
    "    \n",
    "    englishStemmer = SnowballStemmer('english')\n",
    "    \n",
    "    splitted = text.split()\n",
    "    \n",
    "    stemmed_splitted = []\n",
    "    \n",
    "    for word in splitted:\n",
    "        \n",
    "        stemmed_splitted.append(englishStemmer.stem(word))\n",
    "        \n",
    "    stemmed_text = ' '.join(stemmed_splitted)\n",
    "        \n",
    "    return stemmed_text\n",
    "\n",
    "#Применение функции:\n",
    "comments_data['stemmed_text'] = comments_data['text'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>uppercase_ratio</th>\n",
       "      <th>repeat_letters_ratio</th>\n",
       "      <th>exclamation_point_ratio</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064394</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>explan whi the edit made under my usernam hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>daww he match this background colour im seem s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>hey man im realli not tri to edit war it just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>more i cant make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>more i cant make ani real suggest on improv i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>you sir are my hero ani chanc you rememb what ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  uppercase_ratio  \\\n",
       "0  explanation why the edits made under my userna...      0         0.064394   \n",
       "1  daww he matches this background colour im seem...      0         0.071429   \n",
       "2  hey man im really not trying to edit war its j...      0         0.017167   \n",
       "3   more i cant make any real suggestions on impr...      0         0.017685   \n",
       "4  you sir are my hero any chance you remember wh...      0         0.029851   \n",
       "\n",
       "   repeat_letters_ratio  exclamation_point_ratio  \\\n",
       "0              0.007576                 0.000000   \n",
       "1              0.035714                 0.008929   \n",
       "2              0.012876                 0.000000   \n",
       "3              0.020900                 0.000000   \n",
       "4              0.000000                 0.000000   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  explan whi the edit made under my usernam hard...  \n",
       "1  daww he match this background colour im seem s...  \n",
       "2  hey man im realli not tri to edit war it just ...  \n",
       "3  more i cant make ani real suggest on improv i ...  \n",
       "4  you sir are my hero ani chanc you rememb what ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Несколько записей обработанных данных:\n",
    "comments_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10167887648758234"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Доля токсичных комментариев в выборке:\n",
    "len(comments_data[comments_data['toxic'] == 1])/len(comments_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходную выборку теперь нужно разделить на обучающую и тестовую. Преобразования, производимые до этого, не зависели от того скрыта ли тестовая выборка. Далее же признаки будут создаваться на основе известной (обучающей) выборки, а к тестовой будут только применяться подготовленные алгоритмы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отделение признаков от целевого признака:\n",
    "features = comments_data.drop('toxic', axis=1)\n",
    "target = comments_data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделение исходной выборки на обучающую и тестовую с одинаковой долей токсичных комментариев в обеих выборках:\n",
    "features_train_big, features_test, target_train_big, target_test = (\n",
    "    train_test_split(features, target, test_size=0.1, stratify=target, random_state=100)\n",
    ")\n",
    "\n",
    "#Гиперпараметры моделей буду подбирать с помощью валидационной выборки:\n",
    "features_train_small, features_valid, target_train_small, target_valid = (\n",
    "    train_test_split(features_train_big, target_train_big, test_size=0.15, stratify=target_train_big, random_state=200)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я изучил данные в выборке, подготовил комментарии к дальнейшей обработке и выделил три дополнительных признака для обучения. Бегло рассмотрев комментарии, как токсичные, так и корректные, я могу предположить, что проще всего будет находить токсичные: в них часто встречаются одни и те же слова и словосочетания. Корректные же комментарии гораздо более разнообразны и их в выборке большинство - около 90%. Мне кажется, что n-граммы для решения задачи можно не использовать, будет достаточно tf-idf для некоторых слов. Но если n-граммы и добавить для обучения, то можно ограничиться двумя-тремя словами в них.\n",
    "\n",
    "Лемматизацию средствами nltk провести не удалось, потому что модуль wordnetlemmatizer работает только если корректно проставить теги каждому слову. Ограничусь стеммингом с помощью SnowballStemmer из той же библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Загрузка \"стоп-слов\", создание счетчика tf-idf:\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 s, sys: 180 ms, total: 21.1 s\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Подготовка признаков tf-idf для обучения, тюнинга и валидации моделей:\n",
    "tf_idf_train_small = count_tf_idf.fit_transform(features_train_small['stemmed_text'])\n",
    "tf_idf_valid = count_tf_idf.transform(features_valid['stemmed_text'])\n",
    "\n",
    "#Подготовка признаков tf-idf для финального тестирования\n",
    "tf_idf_train_big = count_tf_idf.fit_transform(features_train_big['stemmed_text'])\n",
    "tf_idf_test = count_tf_idf.transform(features_test['stemmed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавление в выборки признаков, созданных в процессе обработки данных:\n",
    "\n",
    "features_train_small = (\n",
    "    hstack([tf_idf_train_small, csr_matrix(np.array(features_train_small[['uppercase_ratio',\n",
    "                                                                          'repeat_letters_ratio',\n",
    "                                                                          'exclamation_point_ratio']]))], format='csr')\n",
    ")\n",
    "\n",
    "features_valid = (\n",
    "    hstack([tf_idf_valid, csr_matrix(np.array(features_valid[['uppercase_ratio',\n",
    "                                                              'repeat_letters_ratio',\n",
    "                                                              'exclamation_point_ratio']]))], format='csr')\n",
    ")\n",
    "\n",
    "features_train_big = (\n",
    "    hstack([tf_idf_train_big, csr_matrix(np.array(features_train_big[['uppercase_ratio',\n",
    "                                                                      'repeat_letters_ratio',\n",
    "                                                                      'exclamation_point_ratio']]))], format='csr')\n",
    ")\n",
    "\n",
    "features_test = (\n",
    "    hstack([tf_idf_test, csr_matrix(np.array(features_test[['uppercase_ratio',\n",
    "                                                            'repeat_letters_ratio',\n",
    "                                                            'exclamation_point_ratio']]))], format='csr')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно приступать к обучению. Пробные запуски показали, что модели с \"деревьями\" обучаются очень долго, а их точность далека до точности линейной регрессии, поэтому далее я поработаю только с линейными моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.19 s, sys: 4.37 s, total: 10.6 s\n",
      "Wall time: 10.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7542671362774316"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Обучение и валидация модели логистической регрессии:\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(features_train_small, target_train_small)\n",
    "predictions = model_lr.predict(features_valid)\n",
    "f1_score(target_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 464 ms, sys: 96 ms, total: 560 ms\n",
      "Wall time: 577 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7397504456327985"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Обучение и валидация модели-перцептрона:\n",
    "model_perc = Perceptron()\n",
    "model_perc.fit(features_train_small, target_train_small)\n",
    "predictions = model_perc.predict(features_valid)\n",
    "f1_score(target_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.76 s, sys: 7.94 ms, total: 2.76 s\n",
      "Wall time: 2.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7104966139954852"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Обучение и валидация модели RidgeClassifier:\n",
    "model_rc = RidgeClassifier()\n",
    "model_rc.fit(features_train_small, target_train_small)\n",
    "predictions = model_rc.predict(features_valid)\n",
    "f1_score(target_valid, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая метрика f1 была достигнута с помощью логистической регрессии, к тому же метрика на неполной выборке выше 0.75, чего нужно добиться на финальном тестировании. Две другие модели показали несколько худший результат. Возможно удастся улучшить метрику, если объединить три эти модели с помощью VotingClassifier - если большинство моделей предсказывают класс 1, то это будет ответом VotingClassifier'а."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.94 s, sys: 4.38 s, total: 14.3 s\n",
      "Wall time: 14.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7656040717921243"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Обучение и валидация модели VotingClassifier:\n",
    "model_vc = VotingClassifier(estimators=[('lr', model_lr), ('perc', model_perc), ('rc', model_rc)],\n",
    "                            voting='hard')\n",
    "\n",
    "model_vc.fit(features_train_small, target_train_small)\n",
    "predictions = model_vc.predict(features_valid)\n",
    "f1_score(target_valid, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно, метрика немного подросла при использовании сразу трех моделей. Некоторые ошибки логистической регрессии исправились совместным \"голосованием\" двух других моделей.\n",
    "\n",
    "Проведу финальную проверку, обучив модель на полной обучающей выборке и проверив на тестовой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 3.97 s, total: 15.4 s\n",
      "Wall time: 15.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7734375000000001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Финальное тестирование модели:\n",
    "model_vc.fit(features_train_big, target_train_big)\n",
    "predictions = model_vc.predict(features_test)\n",
    "f1_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F-мера выше порогового значения - модель пригодна для поиска токсичных комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения задания мне нужно было обработать исходные текстовые данные и подготовить их к обучению. Я постарался избавиться от многих проблем, способных снизить качество моделей: удалил все лишние символы, привел буквы к нижнему регистру, удалил последовательности одних и тех же букв и пр. В комментариях после обработки всё равно остаются некоторые проблемы: слипшиеся слова, сдвоенные буквы, орфографические ошибки - из-за них вычисленные tf-idf не равны истинным значениям. Скорее всего я не заметил еще какие-то особенности текстов, но решение всех проблем заняло бы очень много времени. Вместе с обработкой я выделил три дополнительных признака, не связанных с частотой слов в комментариях, надеюсь они хотя бы немного улучшили итоговую метрику.\n",
    "\n",
    "Сделав несколько пробных прогонов я заметил, что модели с \"деревьями\" обучаются гораздо дольше линейных моделей, а точность их предсказаний ниже. Поэтому я решил обучать только линейные модели. В конце концов обученные модели я объединил в классификатор, предсказывающий класс по \"голосованию\" трех линейных моделей. В ТЗ установлена метрика F1 и пороговое значение 0.75. Финальный классификатор достигает F1 примерно равной 0,773 (при тестовой выборке размером 1/10 от исходной). Теперь модель можно испытать на новых комментариях."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
